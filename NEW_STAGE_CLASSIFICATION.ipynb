{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zyfer416/Construction-analysis/blob/main/NEW_STAGE_CLASSIFICATION.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2htEa5QDMVz",
        "outputId": "f3b57758-6826-487a-d5e4-68d92a0d7ac7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "UewKJEK9WC1f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, models, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from PIL import Image, ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "\n",
        "# Custom loader to fix RGBA warning\n",
        "def pil_loader(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        img = Image.open(f)\n",
        "        return img.convert('RGB')\n",
        "\n",
        "# Transforms\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406],\n",
        "                             [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lmQMHYsOWGpt",
        "outputId": "5f2f3e3a-493e-48d3-8dff-734fcdc95c8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classes: ['Brickwork', 'Foundation', 'Framework', 'Painting', 'Plastering']\n"
          ]
        }
      ],
      "source": [
        "data_dir = '/content/drive/MyDrive/CONSTRUCTION DATASET/Construction_Stages'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          transform=data_transforms[x],\n",
        "                                          loader=pil_loader)\n",
        "                  for x in ['train', 'val']}\n",
        "\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=16, shuffle=True, num_workers=2)\n",
        "               for x in ['train', 'val']}\n",
        "\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "print(f\"Classes: {class_names}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HaRDyOQJYyuq",
        "outputId": "0b492eca-a12e-4f18-e81c-4757e1de22b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 528M/528M [00:04<00:00, 128MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load VGG16 model with pretrained weights\n",
        "weights = models.VGG16_Weights.DEFAULT\n",
        "model = models.vgg16(weights=weights)\n",
        "\n",
        "# Freeze feature extractor parameters\n",
        "for param in model.features.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "# Modify the classifier to match the number of classes\n",
        "num_classes = len(class_names)\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "\n",
        "# Move model to the appropriate device\n",
        "model = model.to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N6z-CeKpZK19"
      },
      "outputs": [],
      "source": [
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer to update only the classifier parameters\n",
        "optimizer = optim.Adam(model.classifier.parameters(), lr=0.0001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdCphIlmZdsr",
        "outputId": "be821037-ffb9-4df0-de9c-dc7ad39b5f14"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.6392 Acc: 0.7553\n",
            "val Loss: 0.7229 Acc: 0.7330\n",
            "Epoch 2/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.1815 Acc: 0.9329\n",
            "val Loss: 0.4719 Acc: 0.8100\n",
            "Epoch 3/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0743 Acc: 0.9755\n",
            "val Loss: 0.4877 Acc: 0.8326\n",
            "Epoch 4/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0323 Acc: 0.9910\n",
            "val Loss: 0.6263 Acc: 0.8009\n",
            "Epoch 5/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0415 Acc: 0.9864\n",
            "val Loss: 0.6462 Acc: 0.8100\n",
            "Epoch 6/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0189 Acc: 0.9935\n",
            "val Loss: 0.7099 Acc: 0.8145\n",
            "Epoch 7/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0270 Acc: 0.9903\n",
            "val Loss: 0.8176 Acc: 0.7919\n",
            "Epoch 8/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0190 Acc: 0.9942\n",
            "val Loss: 0.6636 Acc: 0.8281\n",
            "Epoch 9/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0039 Acc: 0.9981\n",
            "val Loss: 0.8733 Acc: 0.7919\n",
            "Epoch 10/10\n",
            "----------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/PIL/Image.py:1045: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train Loss: 0.0036 Acc: 0.9981\n",
            "val Loss: 1.0046 Acc: 0.7919\n",
            "Training complete!\n"
          ]
        }
      ],
      "source": [
        "# Number of epochs\n",
        "num_epochs = 10\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}')\n",
        "    print('-' * 10)\n",
        "\n",
        "    # Each epoch has a training and validation phase\n",
        "    for phase in ['train', 'val']:\n",
        "        if phase == 'train':\n",
        "            model.train()  # Set model to training mode\n",
        "        else:\n",
        "            model.eval()   # Set model to evaluate mode\n",
        "\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over data\n",
        "        for inputs, labels in dataloaders[phase]:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            with torch.set_grad_enabled(phase == 'train'):\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Backward pass and optimize only in training phase\n",
        "                if phase == 'train':\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "            # Statistics\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss / dataset_sizes[phase]\n",
        "        epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "        print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "print('Training complete!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BRhgXt1hiUl_"
      },
      "outputs": [],
      "source": [
        "torch.save(model.state_dict(), '/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "zLzaXzaYimly",
        "outputId": "4fa3b966-0784-421f-c41f-c0068af85679"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f0294f18-2603-4e67-a51c-def7667de4f8\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f0294f18-2603-4e67-a51c-def7667de4f8\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving IMGGGG.jpg to IMGGGG.jpg\n",
            "\n",
            "ðŸ“‚ Uploaded File: IMGGGG.jpg\n",
            "\n",
            "ðŸ” Raw prediction scores:\n",
            "   Brickwork: 0.0026\n",
            "   Foundation: 0.0000\n",
            "   Framework: 0.0000\n",
            "   Painting: 0.0000\n",
            "   Plastering: 0.9974\n",
            "\n",
            "âœ… Predicted Stage: Plastering\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Reload the model for prediction\n",
        "model = models.vgg16(weights=None)  # No pretrained weights\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define transformation for the input image\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to predict the class of an image\n",
        "def predict_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    print(\"\\nðŸ” Raw prediction scores:\")\n",
        "    for i, prob in enumerate(probs):\n",
        "        print(f\"   {class_names[i]}: {prob:.4f}\")\n",
        "\n",
        "    max_idx = probs.argmax()\n",
        "    print(f\"\\nâœ… Predicted Stage: {class_names[max_idx]}\")\n",
        "\n",
        "# --- Replace Example usage with Uploading Part ---\n",
        "\n",
        "# Upload image interactively\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Predict for each uploaded image\n",
        "for image_name in uploaded.keys():\n",
        "    print(f\"\\nðŸ“‚ Uploaded File: {image_name}\")\n",
        "    predict_image(image_name)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqprnJgkVBYc",
        "outputId": "38a99cca-56ba-4dd5-ad4b-9e3e1a2000f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.3-py3-none-any.whl.metadata (8.7 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.3-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.3\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "!pip install pyngrok\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from flask import Flask, request, render_template, jsonify\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "num_classes = 5  # Update if different\n",
        "class_names = [\"Brickwork\", \"Foundation\", \"Framework\", \"Painting\", \"Plastering\"]\n",
        "\n",
        "model = models.vgg16(weights=None)  # No pretrained weights\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Define image transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Function to make predictions\n",
        "def predict_image(image_path):\n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(image)\n",
        "        probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "\n",
        "    # Get prediction results\n",
        "    predictions = {class_names[i]: float(probs[i]) for i in range(len(class_names))}\n",
        "    predicted_stage = class_names[probs.argmax()]\n",
        "\n",
        "    return predicted_stage, predictions\n",
        "\n",
        "# Route for home page\n",
        "@app.route('/')\n",
        "def index():\n",
        "    return render_template('index.html')\n",
        "\n",
        "# Route for handling image upload\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'file' not in request.files:\n",
        "        return jsonify({\"error\": \"No file uploaded!\"}), 400\n",
        "\n",
        "    file = request.files['file']\n",
        "    if file.filename == '':\n",
        "        return jsonify({\"error\": \"No file selected!\"}), 400\n",
        "\n",
        "    filepath = os.path.join(\"uploads\", file.filename)\n",
        "    file.save(filepath)\n",
        "\n",
        "    predicted_stage, predictions = predict_image(filepath)\n",
        "\n",
        "    return jsonify({\"predicted_stage\": predicted_stage, \"scores\": predictions})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKs4VYwY5y5v",
        "outputId": "aaa5f4bc-0c97-44cc-f155-957fb0fc7d51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Paste your token hereðŸ‘‡\n",
        "ngrok.set_auth_token(\"2vR0ugnAj6bI6pXGpqtbXQP8qGa_6F31ZsEGQFq782HjZFX43\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "4xyzmKlCjhe2",
        "outputId": "396868f2-ccc9-4a9f-c400-1018504a8534"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://2987-34-168-237-86.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import tempfile\n",
        "import subprocess\n",
        "\n",
        "# --- MODEL LOADING ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class_names = ['Brickwork', 'Foundation', 'Framework', 'Painting', 'Plastering']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = models.vgg16(weights=None)  # No pretrained weights\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- FLASK APP ---\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def upload_predict():\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files.get(\"file\")\n",
        "        if file:\n",
        "            try:\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.jpg') as temp_file:\n",
        "                    temp_filename = temp_file.name\n",
        "                    file.save(temp_filename)\n",
        "\n",
        "                image = Image.open(temp_filename).convert('RGB')\n",
        "                image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model(image)\n",
        "                    probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "                max_idx = probs.argmax()\n",
        "                predicted_stage = class_names[max_idx]\n",
        "                raw_scores = {class_names[i]: round(float(probs[i]), 4) for i in range(len(class_names))}\n",
        "\n",
        "                os.remove(temp_filename)\n",
        "\n",
        "                return f'''\n",
        "                <!doctype html>\n",
        "                <html lang=\"en\">\n",
        "                <head>\n",
        "                    <meta charset=\"utf-8\">\n",
        "                    <title>Prediction Result</title>\n",
        "                    <style>\n",
        "                        body {{ text-align: center; padding-top: 50px; font-family: Arial; }}\n",
        "                        .container {{ display: inline-block; padding: 20px; background: #f4f4f4; border-radius: 10px; }}\n",
        "                        h2 {{ color: green; }}\n",
        "                        p {{ font-weight: bold; }}\n",
        "                    </style>\n",
        "                </head>\n",
        "                <body>\n",
        "                    <div class=\"container\">\n",
        "                        <h2>Prediction Done Successfully!</h2>\n",
        "                        <p><strong>Predicted Stage:</strong> {predicted_stage}</p>\n",
        "                        <h4>Raw Prediction Scores:</h4>\n",
        "                        {'<br>'.join([f\"{k}: {v}\" for k, v in raw_scores.items()])}\n",
        "                        <br><br><a href=\"/\">Upload Another Image</a>\n",
        "                    </div>\n",
        "                </body>\n",
        "                </html>\n",
        "                '''\n",
        "            except UnidentifiedImageError:\n",
        "                return \"<h3 style='color:red;'>Error: Unsupported image format. Please upload a valid image.</h3>\"\n",
        "\n",
        "    return '''\n",
        "    <!doctype html>\n",
        "    <html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"utf-8\">\n",
        "        <title>Construction Stage Classifier</title>\n",
        "        <style>\n",
        "            body {{ text-align: center; padding-top: 100px; background-color: #f2f2f2; font-family: Arial, sans-serif; }}\n",
        "            .upload-container {{ display: inline-block; background-color: white; padding: 40px; border-radius: 10px; box-shadow: 0px 0px 10px rgba(0,0,0,0.1); }}\n",
        "            h1 {{ color: #333; }}\n",
        "            input[type=file] {{ margin: 20px 0; }}\n",
        "            button {{\n",
        "                padding: 10px 20px;\n",
        "                background-color: #4CAF50;\n",
        "                color: white;\n",
        "                border: none;\n",
        "                border-radius: 5px;\n",
        "                font-size: 16px;\n",
        "            }}\n",
        "            button:hover {{ background-color: #45a049; }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"upload-container\">\n",
        "            <h1>Construction Stage Classifier</h1>\n",
        "            <form method=\"POST\" enctype=\"multipart/form-data\">\n",
        "                <input type=\"file\" name=\"file\" required><br>\n",
        "                <button type=\"submit\">Predict Stage</button>\n",
        "            </form>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    '''\n",
        "\n",
        "# --- Run Flask app in background ---\n",
        "def run_flask():\n",
        "    app.run(port=5000, use_reloader=False)\n",
        "Thread(target=run_flask).start()\n",
        "\n",
        "# --- Ngrok connection ---\n",
        "subprocess.run([\"pkill\", \"-f\", \"ngrok\"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
        "public_url = ngrok.connect(5000).public_url\n",
        "print(f\"ðŸš€ Public URL: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8XFYMNiCANM",
        "outputId": "e1d08077-5fc9-46cc-c17a-5a03d2ce691a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://382d-34-168-237-86.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, redirect, url_for, session\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "import os\n",
        "import secrets\n",
        "\n",
        "# Flask App Initialization\n",
        "app = Flask(__name__)\n",
        "app.secret_key = secrets.token_hex(16)  # Secret key for session management\n",
        "\n",
        "# --- MODEL LOADING ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "class_names = ['Brickwork', 'Foundation', 'Framework', 'Painting', 'Plastering']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "model = models.vgg16(weights=None)  # No pretrained weights\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Dummy User Data (Replace with Database Later)\n",
        "users = {}\n",
        "\n",
        "# --- ROUTES ---\n",
        "@app.route('/')\n",
        "def home():\n",
        "    if 'user' not in session:\n",
        "        return redirect(url_for('login'))\n",
        "    return render_template('upload.html')\n",
        "\n",
        "@app.route('/login', methods=['GET', 'POST'])\n",
        "def login():\n",
        "    if request.method == 'POST':\n",
        "        username = request.form['username']\n",
        "        password = request.form['password']\n",
        "        if username in users and users[username] == password:\n",
        "            session['user'] = username\n",
        "            return redirect(url_for('home'))\n",
        "        return \"Invalid Credentials! Try Again.\"\n",
        "    return render_template('login.html')\n",
        "\n",
        "@app.route('/signup', methods=['GET', 'POST'])\n",
        "def signup():\n",
        "    if request.method == 'POST':\n",
        "        username = request.form['username']\n",
        "        password = request.form['password']\n",
        "        if username in users:\n",
        "            return \"User already exists!\"\n",
        "        users[username] = password\n",
        "        return redirect(url_for('login'))\n",
        "    return render_template('signup.html')\n",
        "\n",
        "@app.route('/logout')\n",
        "def logout():\n",
        "    session.pop('user', None)\n",
        "    return redirect(url_for('login'))\n",
        "\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    if 'user' not in session:\n",
        "        return redirect(url_for('login'))\n",
        "\n",
        "    file = request.files.get(\"file\")\n",
        "    if file:\n",
        "        filename = file.filename\n",
        "        file.save(filename)\n",
        "        try:\n",
        "            image = Image.open(filename).convert('RGB')\n",
        "            image = transform(image).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image)\n",
        "                probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "            max_idx = probs.argmax()\n",
        "            predicted_stage = class_names[max_idx]\n",
        "            raw_scores = {class_names[i]: round(float(probs[i]), 4) for i in range(len(class_names))}\n",
        "            os.remove(filename)\n",
        "            return render_template('result.html', predicted_stage=predicted_stage, raw_scores=raw_scores)\n",
        "        except UnidentifiedImageError:\n",
        "            return \"Error: Unsupported image format. Please upload a valid image.\"\n",
        "    return redirect(url_for('home'))\n",
        "\n",
        "# --- Run Flask app in background ---\n",
        "def run():\n",
        "    app.run()\n",
        "Thread(target=run).start()\n",
        "\n",
        "# --- Ngrok connection ---\n",
        "ngrok.kill()  # Kill old tunnels\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"\\U0001F680 Public URL: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbh4nj0O8bRa",
        "outputId": "2db84f80-fbad-4e0c-d825-83d36f0d0553"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Paste your token hereðŸ‘‡\n",
        "ngrok.set_auth_token(\"2ulqdKrogU9XaM4sjrLbnXUqKmN_4C482eHJf2W6g8mt8qA3h\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6f-Jcke-4gz",
        "outputId": "a523242d-0f20-4511-bc07-c7aa869432a8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "WARNING:pyngrok.process.ngrok:t=2025-04-08T06:09:01+0000 lvl=warn msg=\"Stopping forwarder\" name=http-5000-ab0d5f8d-12da-4c30-9166-2388602ea671 acceptErr=\"failed to accept connection: Listener closed\"\n",
            "WARNING:pyngrok.process.ngrok:t=2025-04-08T06:09:01+0000 lvl=warn msg=\"Error restarting forwarder\" name=http-5000-ab0d5f8d-12da-4c30-9166-2388602ea671 err=\"failed to start tunnel: session closed\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://15fb-34-168-237-86.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "# --- MODEL LOADING SAME AS YOUR COLAB CODE ---\n",
        "\n",
        "# Device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Class names\n",
        "class_names = ['Brickwork', 'Foundation', 'Framework', 'Painting', 'Plastering']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Load model\n",
        "model = models.vgg16(weights=None)  # No pretrained weights\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# Transform (same as training)\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- FLASK APP ---\n",
        "\n",
        "app = Flask(__name__)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def upload_predict():\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files.get(\"file\")\n",
        "        if file:\n",
        "            filename = file.filename\n",
        "            file.save(filename)\n",
        "\n",
        "            # Preprocess image\n",
        "            image = Image.open(filename).convert('RGB')\n",
        "            image = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "            # Predict\n",
        "            with torch.no_grad():\n",
        "                outputs = model(image)\n",
        "                probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "            max_idx = probs.argmax()\n",
        "            predicted_stage = class_names[max_idx]\n",
        "            raw_scores = {class_names[i]: round(float(probs[i]), 4) for i in range(len(class_names))}\n",
        "\n",
        "            # Remove file after prediction\n",
        "            os.remove(filename)\n",
        "\n",
        "            # Return result page\n",
        "            return f'''\n",
        "            <!doctype html>\n",
        "            <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>Prediction Result</title>\n",
        "                <style>\n",
        "                    body {{ text-align: center; padding-top: 50px; font-family: Arial; }}\n",
        "                    .container {{ display: inline-block; padding: 20px; background: #f4f4f4; border-radius: 10px; }}\n",
        "                    h2 {{ color: green; }}\n",
        "                    p {{ font-weight: bold; }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                <div class=\"container\">\n",
        "                    <h2>Prediction Done Successfully!</h2>\n",
        "                    <p><strong>File Uploaded:</strong> {filename}</p>\n",
        "                    <p><strong>Predicted Stage:</strong> {predicted_stage}</p>\n",
        "                    <h4>Raw Prediction Scores:</h4>\n",
        "                    {\"<br>\".join([f\"{k}: {v}\" for k, v in raw_scores.items()])}\n",
        "                    <br><br><a href=\"/\">Upload Another Image</a>\n",
        "                </div>\n",
        "            </body>\n",
        "            </html>\n",
        "            '''\n",
        "\n",
        "    # --- Upload page ---\n",
        "    return '''\n",
        "<!doctype html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"utf-8\">\n",
        "    <title>Construction Stage Classifier</title>\n",
        "    <style>\n",
        "        body {\n",
        "            text-align: center;\n",
        "            padding-top: 100px;\n",
        "            background-color: #f2f2f2;\n",
        "            font-family: Arial, sans-serif;\n",
        "        }\n",
        "        .upload-container {\n",
        "            display: inline-block;\n",
        "            background-color: white;\n",
        "            padding: 40px;\n",
        "            border-radius: 10px;\n",
        "            box-shadow: 0px 0px 10px rgba(0,0,0,0.1);\n",
        "        }\n",
        "        h1 {\n",
        "            color: #333;\n",
        "        }\n",
        "        input[type=file] {\n",
        "            margin: 20px 0;\n",
        "        }\n",
        "        button {\n",
        "            padding: 10px 20px;\n",
        "            background-color: #4CAF50;\n",
        "            color: white;\n",
        "            border: none;\n",
        "            border-radius: 5px;\n",
        "            font-size: 16px;\n",
        "        }\n",
        "        button:hover {\n",
        "            background-color: #45a049;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body>\n",
        "    <div class=\"upload-container\">\n",
        "        <h1>Construction Stage Classifier</h1>\n",
        "        <form method=\"POST\" enctype=\"multipart/form-data\">\n",
        "            <input type=\"file\" name=\"file\" required><br>\n",
        "            <button type=\"submit\">Predict Stage</button>\n",
        "        </form>\n",
        "    </div>\n",
        "</body>\n",
        "</html>\n",
        "'''\n",
        "\n",
        "# --- Run Flask app in background ---\n",
        "def run():\n",
        "    app.run()\n",
        "\n",
        "Thread(target=run).start()\n",
        "\n",
        "# --- Ngrok connection ---\n",
        "!pkill -f ngrok  # Kill old tunnels\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸš€ Public URL: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdNEFd0oA4_8",
        "outputId": "3a0b7de9-b335-47bf-fef2-78bb104771fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://27f2-34-168-237-86.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NegJerq2A-Ry",
        "outputId": "eabe76d4-eed9-4a48-923e-8c6dae6b2e66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.25M/6.25M [00:00<00:00, 81.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# --- YOLOv8 SETUP ---\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Load YOLOv8 model (you can use yolov8n.pt, yolov8s.pt, etc.)\n",
        "yolo_model = YOLO(\"yolov8n.pt\")  # using the small model for faster inference\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "lZAFo7h_BBYQ",
        "outputId": "b753a685-9a5f-4a85-fa2a-3d8d995066fa"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'filename' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-8896502a0758>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# --- YOLOv8 Detection ---\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0myolo_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_txt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0myolo_output_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0myolo_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_dir\u001b[0m  \u001b[0;31m# path like runs/detect/predict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0myolo_output_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myolo_output_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'filename' is not defined"
          ]
        }
      ],
      "source": [
        "# --- YOLOv8 Detection ---\n",
        "yolo_results = yolo_model.predict(source=filename, conf=0.4, save=True, save_txt=False)\n",
        "yolo_output_dir = yolo_results[0].save_dir  # path like runs/detect/predict\n",
        "yolo_output_img = os.path.join(yolo_output_dir, os.path.basename(filename))\n",
        "\n",
        "# Copy YOLO image to working dir so Flask can serve it\n",
        "output_img_path = \"detected_\" + filename\n",
        "os.rename(yolo_output_img, output_img_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2_qyiskiBGm-",
        "outputId": "62de2cdf-9e1f-4935-c245-5e23ce847900"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ðŸš€ Public URL: NgrokTunnel: \"https://de4e-34-168-237-86.ngrok-free.app\" -> \"http://localhost:5000\"\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, request, send_from_directory\n",
        "from threading import Thread\n",
        "from pyngrok import ngrok\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# --- Device Setup ---\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# --- Class Names for VGG16 ---\n",
        "class_names = ['Brickwork', 'Foundation', 'Framework', 'Painting', 'Plastering']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# --- Load VGG16 Model ---\n",
        "model = models.vgg16(weights=None)\n",
        "model.classifier[6] = nn.Linear(model.classifier[6].in_features, num_classes)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/CONSTRUCTION DATASET/vgg16_multiclass.pth', map_location=device))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# --- Load YOLOv8 Model ---\n",
        "yolo_model = YOLO('yolov8n.pt')  # Change to yolov8s.pt or yolov8m.pt if needed\n",
        "\n",
        "# --- Transform for VGG ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# --- Flask App ---\n",
        "app = Flask(__name__)\n",
        "UPLOAD_FOLDER = '/content/uploads'\n",
        "os.makedirs(UPLOAD_FOLDER, exist_ok=True)\n",
        "\n",
        "@app.route(\"/\", methods=[\"GET\", \"POST\"])\n",
        "def upload_predict():\n",
        "    if request.method == \"POST\":\n",
        "        file = request.files.get(\"file\")\n",
        "        if file:\n",
        "            filename = file.filename\n",
        "            file_path = os.path.join(UPLOAD_FOLDER, filename)\n",
        "            file.save(file_path)\n",
        "\n",
        "            # VGG16 Classification\n",
        "            image = Image.open(file_path).convert('RGB')\n",
        "            vgg_input = transform(image).unsqueeze(0).to(device)\n",
        "            with torch.no_grad():\n",
        "                outputs = model(vgg_input)\n",
        "                probs = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "            max_idx = probs.argmax()\n",
        "            predicted_stage = class_names[max_idx]\n",
        "            raw_scores = {class_names[i]: round(float(probs[i]), 4) for i in range(len(class_names))}\n",
        "\n",
        "            # YOLOv8 Detection\n",
        "            detection_results = yolo_model.predict(source=file_path, save=True, conf=0.3)\n",
        "            yolo_save_path = detection_results[0].save_dir\n",
        "            yolo_output_img_path = os.path.join(yolo_save_path, filename)\n",
        "\n",
        "            return f'''\n",
        "            <!doctype html>\n",
        "            <html lang=\"en\">\n",
        "            <head>\n",
        "                <meta charset=\"utf-8\">\n",
        "                <title>Prediction Result</title>\n",
        "                <style>\n",
        "                    body {{ text-align: center; padding-top: 50px; font-family: Arial; }}\n",
        "                    .container {{ display: inline-block; padding: 20px; background: #f4f4f4; border-radius: 10px; }}\n",
        "                    h2 {{ color: green; }}\n",
        "                    p {{ font-weight: bold; }}\n",
        "                    img {{ max-width: 90%; margin-top: 20px; border: 1px solid #ccc; border-radius: 10px; }}\n",
        "                </style>\n",
        "            </head>\n",
        "            <body>\n",
        "                <div class=\"container\">\n",
        "                    <h2>Prediction Completed</h2>\n",
        "                    <p><strong>File:</strong> {filename}</p>\n",
        "                    <p><strong>Predicted Stage:</strong> {predicted_stage}</p>\n",
        "                    <h4>Raw Prediction Scores:</h4>\n",
        "                    {\"<br>\".join([f\"{k}: {v}\" for k, v in raw_scores.items()])}\n",
        "                    <h4>Detected Objects:</h4>\n",
        "                    <img src=\"/files/{filename}\" alt=\"YOLOv8 Detection Output\">\n",
        "                    <br><br><a href=\"/\">ðŸ” Upload Another Image</a>\n",
        "                </div>\n",
        "            </body>\n",
        "            </html>\n",
        "            '''\n",
        "\n",
        "    return '''\n",
        "    <!doctype html>\n",
        "    <html lang=\"en\">\n",
        "    <head>\n",
        "        <meta charset=\"utf-8\">\n",
        "        <title>Construction Stage + Object Detection</title>\n",
        "        <style>\n",
        "            body {{\n",
        "                text-align: center;\n",
        "                padding-top: 100px;\n",
        "                background-color: #f0f0f0;\n",
        "                font-family: Arial, sans-serif;\n",
        "            }}\n",
        "            .upload-box {{\n",
        "                display: inline-block;\n",
        "                background-color: white;\n",
        "                padding: 40px;\n",
        "                border-radius: 10px;\n",
        "                box-shadow: 0px 0px 10px rgba(0,0,0,0.1);\n",
        "            }}\n",
        "            h1 {{ color: #333; }}\n",
        "            input[type=file] {{ margin: 20px 0; }}\n",
        "            button {{\n",
        "                padding: 10px 20px;\n",
        "                background-color: #4CAF50;\n",
        "                color: white;\n",
        "                border: none;\n",
        "                border-radius: 5px;\n",
        "                font-size: 16px;\n",
        "            }}\n",
        "            button:hover {{ background-color: #45a049; }}\n",
        "        </style>\n",
        "    </head>\n",
        "    <body>\n",
        "        <div class=\"upload-box\">\n",
        "            <h1>Construction Stage + Object Detector</h1>\n",
        "            <form method=\"POST\" enctype=\"multipart/form-data\">\n",
        "                <input type=\"file\" name=\"file\" required><br>\n",
        "                <button type=\"submit\">Predict</button>\n",
        "            </form>\n",
        "        </div>\n",
        "    </body>\n",
        "    </html>\n",
        "    '''\n",
        "\n",
        "# Serve YOLO output image\n",
        "@app.route(\"/files/<filename>\")\n",
        "def send_file(filename):\n",
        "    yolo_output_dir = yolo_model.predict(source=UPLOAD_FOLDER, save=True, conf=0.3)[0].save_dir\n",
        "    return send_from_directory(yolo_output_dir, filename)\n",
        "\n",
        "# Launch Flask in thread\n",
        "def run():\n",
        "    app.run()\n",
        "\n",
        "Thread(target=run).start()\n",
        "\n",
        "# Kill old tunnels if any, then start Ngrok\n",
        "!pkill -f ngrok\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"ðŸš€ Public URL: {public_url}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "02KjbCDwBMDH",
        "outputId": "3b39020f-ffef-49c9-88ab-80ffef97abc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Address already in use\n",
            "Port 5000 is in use by another program. Either identify and stop that program, or start the server with a different port.\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\", line 759, in __init__\n",
            "    self.server_bind()\n",
            "  File \"/usr/lib/python3.11/http/server.py\", line 136, in server_bind\n",
            "    socketserver.TCPServer.server_bind(self)\n",
            "  File \"/usr/lib/python3.11/socketserver.py\", line 472, in server_bind\n",
            "    self.socket.bind(self.server_address)\n",
            "OSError: [Errno 98] Address already in use\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-21-16e30b4b66d7>\", line 2, in <cell line: 0>\n",
            "    app.run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\", line 88, in new_run\n",
            "    old_run()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/flask/app.py\", line 662, in run\n",
            "    run_simple(t.cast(str, host), port, self, **options)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\", line 1093, in run_simple\n",
            "    srv = make_server(\n",
            "          ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\", line 930, in make_server\n",
            "    return ThreadedWSGIServer(\n",
            "           ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\", line 782, in __init__\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1671, in getframeinfo\n",
            "    lineno = frame.f_lineno\n",
            "             ^^^^^^^^^^^^^^\n",
            "AttributeError: 'tuple' object has no attribute 'f_lineno'\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_activate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/http/server.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;34m\"\"\"Override server_bind to store the server name.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0msocketserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTCPServer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_bind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m         \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/socketserver.py\u001b[0m in \u001b[0;36mserver_bind\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetsockopt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSOL_SOCKET\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSO_REUSEPORT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver_address\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsockname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: [Errno 98] Address already in use",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-16e30b4b66d7>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flask_ngrok.py\u001b[0m in \u001b[0;36mnew_run\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0mold_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/flask/app.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, host, port, debug, load_dotenv, **options)\u001b[0m\n\u001b[1;32m    661\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 662\u001b[0;31m             \u001b[0mrun_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    663\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mrun_simple\u001b[0;34m(hostname, port, application, use_reloader, use_debugger, use_evalex, extra_files, exclude_patterns, reloader_interval, reloader_type, threaded, processes, request_handler, static_files, passthrough_errors, ssl_context)\u001b[0m\n\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1093\u001b[0;31m     srv = make_server(\n\u001b[0m\u001b[1;32m   1094\u001b[0m         \u001b[0mhostname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36mmake_server\u001b[0;34m(host, port, app, threaded, processes, request_handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    929\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mthreaded\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 930\u001b[0;31m         return ThreadedWSGIServer(\n\u001b[0m\u001b[1;32m    931\u001b[0m             \u001b[0mhost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mport\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_handler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpassthrough_errors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mssl_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/werkzeug/serving.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, host, port, app, handler, passthrough_errors, ssl_context, fd)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 782\u001b[0;31m                 \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    783\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyNNCzDMZeXqTOKHOtRsyBt0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}